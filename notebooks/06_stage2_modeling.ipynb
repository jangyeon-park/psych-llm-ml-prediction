{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e452bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.config import PROJECT_ROOT, MODEL_SEED, LABELS, MODELS_TO_RUN\n",
    "from src.variables import LLM_COLS, LAB_COLS, CODE_COLS, CATEGORY_COLS\n",
    "from src.preprocessing import create_preprocessor\n",
    "from src.models import get_models_and_search_space\n",
    "from src.evaluation import youden_threshold, metrics_at_threshold, decision_curve\n",
    "from src.feature_utils import (\n",
    "    find_feature_list_file, read_feature_list, load_xy,\n",
    "    load_feature_name_map, prettify_name, prettify_names,\n",
    "    clean_ct_feature_name, inject_psych_scale_aliases, prettify_psych_name,\n",
    "    FRIENDLY_OVERRIDES, LEVEL_MAP, to_bayes_space\n",
    ")\n",
    "\n",
    "import os, re, joblib, json, glob, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, brier_score_loss,\n",
    "    precision_recall_fscore_support, accuracy_score, precision_score,\n",
    "    recall_score, f1_score, roc_curve, confusion_matrix,\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "plt.rcParams.update({\"figure.dpi\": 130, \"axes.spines.top\": False, \"axes.spines.right\": False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# âš ï¸âš ï¸âš ï¸âš ï¸0) ê²½ë¡œ/ì¡°í•© ì„¤ì •âš ï¸âš ï¸âš ï¸âš ï¸\n",
    "# ---------------------------\n",
    "OUT_DIR = Path(\n",
    "    str(PROJECT_ROOT / \"results/new_analysis/260114_qwen/modeling/step2_modeling/simple_20\")\n",
    ")\n",
    "FIG_DIR = OUT_DIR / \"figures\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMP_DIR = Path(\n",
    "    str(PROJECT_ROOT / \"data/processed_imp/260114_split_corr_LLM_ADER/imputation/simple_imput\")\n",
    ")\n",
    "FS_DIR = Path(\n",
    "    str(PROJECT_ROOT / \"results/new_analysis/260114_qwen/Feature_Selection/simple_20/step2_FS\")\n",
    ")\n",
    "\n",
    "# âš ï¸Train/Test íŒŒì¼ ì´ë¦„âš ï¸\n",
    "DATA_FILES = {\n",
    "    \"label_30d\": {\n",
    "        \"train\": IMP_DIR / \"simple_label_30d_train.csv\",\n",
    "        \"test\": IMP_DIR / \"simple_label_30d_test.csv\",\n",
    "    },\n",
    "    \"label_60d\": {\n",
    "        \"train\": IMP_DIR / \"simple_label_60d_train.csv\",\n",
    "        \"test\": IMP_DIR / \"simple_label_60d_test.csv\",\n",
    "    },\n",
    "    \"label_90d\": {\n",
    "        \"train\": IMP_DIR / \"simple_label_90d_train.csv\",\n",
    "        \"test\": IMP_DIR / \"simple_label_90d_test.csv\",\n",
    "    },\n",
    "    \"label_180d\": {\n",
    "        \"train\": IMP_DIR / \"simple_label_180d_train.csv\",\n",
    "        \"test\": IMP_DIR / \"simple_label_180d_test.csv\",\n",
    "    },\n",
    "    \"label_365d\": {\n",
    "        \"train\": IMP_DIR / \"simple_label_365d_train.csv\",\n",
    "        \"test\": IMP_DIR / \"simple_label_365d_test.csv\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# ë‹¹ì‹ ì˜ íƒìƒ‰ ê²°ê³¼ë¥¼ ë°˜ì˜í•œ ê¶Œì¥ì¡°í•© (í•„ìš”ì‹œ ìˆ˜ì •)\n",
    "BEST_COMBOS = {\n",
    "    \"label_30d\": {\"model\": \"rf\", \"feature_set\": \"All_Features\"},\n",
    "    \"label_60d\": {\"model\": \"rf\", \"feature_set\": \"All_Features\"},\n",
    "    \"label_90d\": {\"model\": \"rf\", \"feature_set\": \"All_Features\"},\n",
    "    \"label_180d\": {\"model\": \"rf\", \"feature_set\": \"All_Features\"},\n",
    "    \"label_365d\": {\"model\": \"rf\", \"feature_set\": \"All_Features\"},\n",
    "}\n",
    "\n",
    "TARGET_COL_FALLBACK = \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79530cc1",
   "metadata": {},
   "source": [
    "# Variables imported from `src.variables`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab015a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_MAP_CSV = str(PROJECT_ROOT / \"results/Feature_selection/w_LLM_v5/step2_FS/feature_summary.csv\")\n",
    "NAME_MAP = load_feature_name_map(FEATURE_MAP_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38bd2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 4) Nested-CV on TRAIN â†’ TEST í‰ê°€\n",
    "# ---------------------------\n",
    "def run_for_label(\n",
    "    label: str, model_name: str, feature_set: str, random_state: int = 42\n",
    ") -> Dict:\n",
    "    print(f\"\\n==== {label} | model={model_name} | features={feature_set}====\")\n",
    "    # FS\n",
    "    fs_file = find_feature_list_file(label, FS_DIR)\n",
    "    fs_feats = read_feature_list(fs_file)\n",
    "\n",
    "    # --- feature_setì— ë”°ë¼ LLM/Lab ì»¬ëŸ¼ ì¶”ê°€ ---\n",
    "    fs_low = feature_set.lower()\n",
    "    base_features = list(fs_feats)  # ì›ë³¸ FS ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "    if fs_low == \"all_features\":\n",
    "        # 1) All_Features: ë¶ˆëŸ¬ì˜¨ FS + LLM\n",
    "        # (ì •ì˜: ë¶ˆëŸ¬ì˜¨ feature íŒŒì¼ì—ì„œ LLM colsë§Œ ì¶”ê°€)\n",
    "        final_features_list = [*base_features, *LLM_COLS]\n",
    "\n",
    "    elif fs_low == \"base_lab\":\n",
    "        # 2) Base_Lab: ë¶ˆëŸ¬ì˜¨ FS ê·¸ëŒ€ë¡œ\n",
    "        # (ì •ì˜: ê·¸ëƒ¥ ë¶ˆëŸ¬ì˜¨ feature íŒŒì¼ ì‚¬ìš©)\n",
    "        final_features_list = base_features\n",
    "\n",
    "    elif fs_low == \"base\":\n",
    "        # 3) Base: ë¶ˆëŸ¬ì˜¨ FSì—ì„œ Lab ì œì™¸\n",
    "        # (ì •ì˜: ë¶ˆëŸ¬ì˜¨ feature íŒŒì¼ì—ì„œ lab_colsì— í•´ë‹¹í•˜ëŠ” ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ ì œì™¸)\n",
    "        lab_cols_set = set(LAB_COLS)\n",
    "        final_features_list = [f for f in base_features if f not in lab_cols_set]\n",
    "\n",
    "    elif fs_low == \"base_llm\":\n",
    "        # 4) Base_LLM: ë¶ˆëŸ¬ì˜¨ FSì—ì„œ Lab ì œì™¸ + LLM ì¶”ê°€\n",
    "        # (ì •ì˜: ë¶ˆëŸ¬ì˜¨ feature íŒŒì¼ì—ì„œ lab_cols ì œì™¸í•˜ê³  LLM cols ì¶”ê°€)\n",
    "        lab_cols_set = set(LAB_COLS)\n",
    "        base_only = [f for f in base_features if f not in lab_cols_set]\n",
    "        final_features_list = [*base_only, *LLM_COLS]\n",
    "\n",
    "    else:\n",
    "        # ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš°, ê¸°ë³¸ 'Base_Lab'ìœ¼ë¡œ ë™ì‘ (fs_feats ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n",
    "        print(\n",
    "            f\"[Warning] Unknown feature_set '{feature_set}'. Defaulting to 'Base_Lab' logic (using fs_feats as-is).\"\n",
    "        )\n",
    "        final_features_list = base_features\n",
    "\n",
    "    # ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)\n",
    "    features_final = list(dict.fromkeys(final_features_list))\n",
    "\n",
    "    print(f\"  [Info] Using {len(features_final)} features for '{feature_set}'.\")\n",
    "\n",
    "    # Load Train/Test\n",
    "    train_path = DATA_FILES[label][\"train\"]\n",
    "    test_path = DATA_FILES[label][\"test\"]\n",
    "    X_tr, y_tr = load_xy(train_path, label, features_final)\n",
    "    X_te, y_te = load_xy(test_path, label, features_final)\n",
    "\n",
    "    # --- ì „ì²˜ë¦¬ê¸°: ì¹´í…Œê³ ë¦¬/ì½”ë“œ/ìˆ˜ì¹˜ ë¶„ë¦¬ (êµì§‘í•©ë§Œ) ---\n",
    "    # LLM/CATEGORY/CODE ë¦¬ìŠ¤íŠ¸ ì¤‘ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ ì‚¬ìš©\n",
    "    categorical_features = [c for c in CATEGORY_COLS if c in X_tr.columns]\n",
    "    code_features = [c for c in CODE_COLS if c in X_tr.columns]\n",
    "    # ìˆ˜ì¹˜í˜• = ë‚˜ë¨¸ì§€\n",
    "    numeric_features = [\n",
    "        c for c in X_tr.columns if c not in set(categorical_features + code_features)\n",
    "    ]\n",
    "\n",
    "    preprocessor = create_preprocessor(\n",
    "        numeric_features=numeric_features,\n",
    "        categorical_features=categorical_features,\n",
    "        code_features=code_features,\n",
    "    )\n",
    "\n",
    "    # --- ëª¨ë¸ & íƒìƒ‰ê³µê°„ ---\n",
    "    models = get_models_and_search_space()\n",
    "    clf, grid = models[model_name.upper()]\n",
    "    search_space = to_bayes_space(grid)\n",
    "\n",
    "    # Pipeline (selector â†’ SMOTE â†’ estimator[+scaler])\n",
    "    pipe = ImbPipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"smote\", SMOTE(sampling_strategy=\"minority\", random_state=42)),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Inner search\n",
    "    inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "    search = BayesSearchCV(\n",
    "        estimator=pipe,\n",
    "        search_spaces=search_space,\n",
    "        n_iter=50,  # code test : 5, Real test : 30 or 50\n",
    "        cv=inner,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1,\n",
    "        random_state=random_state,\n",
    "        refit=True,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Outer CV on Train (OOF)\n",
    "    outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    oof_prob = np.zeros(len(y_tr))\n",
    "    oof_pred = np.zeros(len(y_tr), dtype=int)\n",
    "    oof_fold = np.zeros(len(y_tr), dtype=int)\n",
    "\n",
    "    fold_metrics = []\n",
    "    for f, (tr_idx, va_idx) in enumerate(outer.split(X_tr, y_tr), start=1):\n",
    "        X_tr_i, X_va_i = X_tr.iloc[tr_idx], X_tr.iloc[va_idx]\n",
    "        y_tr_i, y_va_i = y_tr.iloc[tr_idx], y_tr.iloc[va_idx]\n",
    "        search.fit(X_tr_i, y_tr_i)\n",
    "        best = search.best_estimator_\n",
    "\n",
    "        proba = best.predict_proba(X_va_i)[:, 1]\n",
    "        pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "        oof_prob[va_idx] = proba\n",
    "        oof_pred[va_idx] = pred\n",
    "        oof_fold[va_idx] = f\n",
    "\n",
    "        auc = roc_auc_score(y_va_i, proba)\n",
    "        prauc = average_precision_score(y_va_i, proba)\n",
    "        brier = brier_score_loss(y_va_i, proba)\n",
    "        acc = accuracy_score(y_va_i, pred)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_va_i, pred, average=\"binary\", zero_division=0\n",
    "        )\n",
    "\n",
    "        fold_metrics.append(\n",
    "            {\n",
    "                \"label\": label,\n",
    "                \"fold\": f,\n",
    "                \"model\": model_name,\n",
    "                \"auc\": auc,\n",
    "                \"prauc\": prauc,\n",
    "                \"brier\": brier,\n",
    "                \"accuracy\": acc,\n",
    "                \"precision\": prec,\n",
    "                \"recall\": rec,\n",
    "                \"f1\": f1,\n",
    "                \"best_params\": search.best_params_,\n",
    "            }\n",
    "        )\n",
    "        print(f\"  [Outer {f}] AUC={auc:.3f} | PR-AUC={prauc:.3f} | F1={f1:.3f}\")\n",
    "\n",
    "    # ì €ì¥: OOF & Fold metrics & summary\n",
    "    oof_df = pd.DataFrame(\n",
    "        {\n",
    "            \"label\": label,\n",
    "            \"oof_fold\": oof_fold,\n",
    "            \"y_true\": y_tr.values,\n",
    "            \"y_prob\": oof_prob,\n",
    "            \"y_pred\": oof_pred,\n",
    "        }\n",
    "    )\n",
    "    oof_df.to_csv(OUT_DIR / f\"{label}__oof_predictions.csv\", index=False)\n",
    "\n",
    "    fold_df = pd.DataFrame(fold_metrics)\n",
    "    fold_df.to_csv(OUT_DIR / f\"{label}__train_fold_metrics.csv\", index=False)\n",
    "\n",
    "    train_summary = (\n",
    "        fold_df.agg(\n",
    "            {\n",
    "                \"auc\": [\"mean\", \"std\"],\n",
    "                \"prauc\": [\"mean\", \"std\"],\n",
    "                \"brier\": [\"mean\", \"std\"],\n",
    "                \"accuracy\": [\"mean\", \"std\"],\n",
    "                \"precision\": [\"mean\", \"std\"],\n",
    "                \"recall\": [\"mean\", \"std\"],\n",
    "                \"f1\": [\"mean\", \"std\"],\n",
    "            }\n",
    "        )\n",
    "        .T.reset_index()\n",
    "        .rename(columns={\"index\": \"metric\"})\n",
    "    )\n",
    "    train_summary.insert(0, \"split\", \"train_oof\")\n",
    "    train_summary.insert(0, \"model\", model_name)\n",
    "    train_summary.insert(0, \"label\", label)\n",
    "\n",
    "    # OOF meanÂ±SD ìš”ì•½ ì €ì¥ (Nested-CV ê²°ê³¼ ì œì‹œìš©)\n",
    "    train_summary.to_csv(OUT_DIR / f\"{label}__train_oof_summary.csv\", index=False)\n",
    "\n",
    "    # â­ï¸â­ï¸â­ï¸ --- (A) OOFì—ì„œ Youden index ê¸°ë°˜ ìµœì  threshold --- â­ï¸â­ï¸â­ï¸\n",
    "    thr_oof, tpr_oof, fpr_oof = youden_threshold(\n",
    "        oof_df[\"y_true\"].values, oof_df[\"y_prob\"].values\n",
    "    )\n",
    "    youden_oof = tpr_oof - fpr_oof\n",
    "    oof_thr_metrics = metrics_at_threshold(\n",
    "        oof_df[\"y_true\"].values, oof_df[\"y_prob\"].values, thr_oof\n",
    "    )\n",
    "\n",
    "    # ì €ì¥\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"label\": label,\n",
    "                \"model\": model_name,\n",
    "                \"split\": \"train_oof\",\n",
    "                \"youden_index\": youden_oof,\n",
    "                **oof_thr_metrics,\n",
    "            }\n",
    "        ]\n",
    "    ).to_csv(OUT_DIR / f\"{label}__youden_metrics_OOF.csv\", index=False)\n",
    "    # â­ï¸â­ï¸â­ï¸ --- (A) OOFì—ì„œ Youden index ê¸°ë°˜ ìµœì  threshold --- â­ï¸â­ï¸â­ï¸\n",
    "\n",
    "    # OOF ROC / Calibration / DCA\n",
    "    fpr, tpr, _ = roc_curve(oof_df[\"y_true\"], oof_df[\"y_prob\"])\n",
    "    auc_oof = roc_auc_score(oof_df[\"y_true\"], oof_df[\"y_prob\"])\n",
    "    plt.figure(figsize=(4.6, 4.2))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"AUC={auc_oof:.3f}\")\n",
    "    plt.plot([0, 1], [0, 1], \"--\")\n",
    "    # â­ï¸â­ï¸â­ï¸Youden ìµœì ì  í‘œì‹œ â­ï¸â­ï¸â­ï¸\n",
    "    plt.scatter(\n",
    "        [fpr_oof], [tpr_oof], s=30, marker=\"o\", label=f\"Youden*: thr={thr_oof:.3f}\"\n",
    "    )\n",
    "    # â­ï¸â­ï¸â­ï¸Youden ìµœì ì  í‘œì‹œ â­ï¸â­ï¸â­ï¸\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC (OOF) - {label} ({model_name})\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / f\"{label}__ROC_OOF.png\")\n",
    "    plt.close()\n",
    "\n",
    "    pt, pp = calibration_curve(oof_df[\"y_true\"], oof_df[\"y_prob\"], n_bins=10)\n",
    "    plt.figure(figsize=(4.6, 4.2))\n",
    "    plt.plot(pp, pt, marker=\"o\")\n",
    "    plt.plot([0, 1], [0, 1], \"--\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Observed\")\n",
    "    plt.title(\n",
    "        f\"Calibration (OOF) - {label} ({model_name})\\nBrier={brier_score_loss(oof_df['y_true'], oof_df['y_prob']):.3f}\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / f\"{label}__Calibration_OOF.png\")\n",
    "    plt.close()\n",
    "\n",
    "    dca_oof = decision_curve(oof_df[\"y_true\"].values, oof_df[\"y_prob\"].values)\n",
    "    plt.figure(figsize=(4.6, 4.2))\n",
    "    plt.plot(dca_oof[\"threshold\"], dca_oof[\"net_benefit\"], lw=2, label=\"Model\")\n",
    "    prev = oof_df[\"y_true\"].mean()\n",
    "    treat_all = dca_oof[\"threshold\"].apply(\n",
    "        lambda th: prev - (1 - prev) * (th / (1 - th))\n",
    "    )\n",
    "    plt.plot(dca_oof[\"threshold\"], treat_all, \"--\", label=\"Treat-all\")\n",
    "    plt.plot(\n",
    "        dca_oof[\"threshold\"],\n",
    "        np.zeros_like(dca_oof[\"threshold\"]),\n",
    "        \"--\",\n",
    "        label=\"Treat-none\",\n",
    "    )\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Net benefit\")\n",
    "    plt.title(f\"DCA (OOF) - {label} ({model_name})\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / f\"{label}__DCA_OOF.png\")\n",
    "    plt.close()\n",
    "    dca_oof.to_csv(OUT_DIR / f\"{label}__DCA_OOF.csv\", index=False)\n",
    "\n",
    "    # Train fullë¡œ ì¬í•™ìŠµ â†’ Test í‰ê°€\n",
    "    print(\"  [Final fit on full Train] ...\")\n",
    "    search.fit(X_tr, y_tr)\n",
    "    best_full = search.best_estimator_\n",
    "\n",
    "    # --- â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ ---\n",
    "    # --- â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ ---\n",
    "    # (A) ìµœì¢… íŒŒì´í”„ë¼ì¸ ì €ì¥ (preprocessor + SMOTE + clf ëª¨ë‘ í¬í•¨)\n",
    "    model_path = OUT_DIR / f\"{label}__best_model.pkl\"\n",
    "    joblib.dump(best_full, model_path)\n",
    "\n",
    "    # (B) ì´ ë¼ë²¨ì—ì„œ ì‹¤ì œë¡œ ì‚¬ìš©í•œ \"ì›ë³¸ ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸\" ì €ì¥ (ì¬í˜„ìš©)\n",
    "    features_path = OUT_DIR / f\"{label}__features_final.json\"\n",
    "    with open(features_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(features_final, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # (C) ì „ì²˜ë¦¬ í›„ í”¼ì²˜ëª… ì €ì¥ (ì›í•« í¬í•¨ëœ ìµœì¢… ì…ë ¥ í”¼ì²˜ëª…)\n",
    "    preproc = best_full.named_steps[\"preprocessor\"]\n",
    "    try:\n",
    "        raw_names = list(preproc.get_feature_names_out())\n",
    "    except Exception:\n",
    "        raw_names = [f\"f{i}\" for i in range(preproc.transform(X_tr.iloc[:1]).shape[1])]\n",
    "\n",
    "    # ì ‘ë‘ì‚¬ ì •ë¦¬(ì„ íƒ): num__/cat__/code__ ë° num_/cat_/code_ ì œê±°\n",
    "\n",
    "\n",
    "    feat_names_clean = prettify_names(raw_names, NAME_MAP)\n",
    "    featnames_path = OUT_DIR / f\"{label}__transformed_feature_names.json\"\n",
    "    with open(featnames_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(feat_names_clean, f, ensure_ascii=False, indent=2)\n",
    "    # --- â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ ---\n",
    "    # --- â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ ---\n",
    "\n",
    "    # --- â­ï¸â­ï¸â­ï¸ (ì¶”ê°€) ìµœì¢… ëª¨ë¸ì˜ best_params ì €ì¥ â­ï¸â­ï¸â­ï¸ ---\n",
    "    final_best_params = search.best_params_\n",
    "    pd.DataFrame([{\"label\": label, \"model\": model_name, **final_best_params}]).to_csv(\n",
    "        OUT_DIR / f\"{label}__best_params_final.csv\", index=False\n",
    "    )\n",
    "\n",
    "    prob_te = best_full.predict_proba(X_te)[:, 1]\n",
    "    pred_te = (prob_te >= thr_oof).astype(int)\n",
    "\n",
    "    # Test metrics\n",
    "    auc_te = roc_auc_score(y_te, prob_te)\n",
    "    pr_te = average_precision_score(y_te, prob_te)\n",
    "    brier_te = brier_score_loss(y_te, prob_te)\n",
    "    acc_te = accuracy_score(y_te, pred_te)\n",
    "    prec_te, rec_te, f1_te, _ = precision_recall_fscore_support(\n",
    "        y_te, pred_te, average=\"binary\", zero_division=0\n",
    "    )\n",
    "\n",
    "    # --- â­ï¸â­ï¸â­ï¸ Youden(Test) ë¨¼ì € ê³„ì‚° â†’ ì´í›„ test_metricsì— í•©ì¹˜ê¸° â­ï¸â­ï¸â­ï¸ ---\n",
    "    thr_te, tpr_te, fpr_te = youden_threshold(y_te.values, prob_te)\n",
    "    youden_te = tpr_te - fpr_te\n",
    "    test_thr_metrics = metrics_at_threshold(y_te.values, prob_te, thr_te)\n",
    "\n",
    "    test_metrics = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"label\": label,\n",
    "                \"model\": model_name,\n",
    "                \"split\": \"test\",\n",
    "                \"auc\": auc_te,\n",
    "                \"prauc\": pr_te,\n",
    "                \"brier\": brier_te,\n",
    "                \"accuracy\": acc_te,\n",
    "                \"precision\": prec_te,\n",
    "                \"recall\": rec_te,\n",
    "                \"f1\": f1_te,\n",
    "                \"best_params\": search.best_params_,\n",
    "                \"youden_index\": youden_te,\n",
    "                \"thr_youden\": thr_te,\n",
    "                \"sens_at_thr\": test_thr_metrics[\"sensitivity\"],\n",
    "                \"spec_at_thr\": test_thr_metrics[\"specificity\"],\n",
    "                \"ppv_at_thr\": test_thr_metrics[\"ppv\"],\n",
    "                \"npv_at_thr\": test_thr_metrics[\"npv\"],\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    test_metrics.to_csv(OUT_DIR / f\"{label}__test_metrics.csv\", index=False)\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"label\": label,\n",
    "                \"model\": model_name,\n",
    "                \"split\": \"test\",\n",
    "                \"youden_index\": youden_te,\n",
    "                **test_thr_metrics,\n",
    "            }\n",
    "        ]\n",
    "    ).to_csv(OUT_DIR / f\"{label}__youden_metrics_Test.csv\", index=False)\n",
    "\n",
    "    # --- ë³€ê²½: OOF ì„ê³„ê°’(thr_oof) ê¸°ì¤€ì„ ë©”ì¸ìœ¼ë¡œ ë³´ê³  ---\n",
    "    # (1) OOF ì„ê³„ê°’ìœ¼ë¡œ Test ì§€í‘œ ê³„ì‚° â†’ ë©”ì¸ ë³´ê³ \n",
    "    test_thr_metrics_oof = metrics_at_threshold(y_te.values, prob_te, thr_oof)\n",
    "    test_metrics = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"label\": label,\n",
    "                \"model\": model_name,\n",
    "                \"split\": \"test\",\n",
    "                \"auc\": auc_te,\n",
    "                \"prauc\": pr_te,\n",
    "                \"brier\": brier_te,\n",
    "                # ë¶„ë¥˜ ì§€í‘œë„ thr_oof ê¸°ì¤€ìœ¼ë¡œ ì¬ê³„ì‚°í•´ ë°˜ì˜\n",
    "                \"accuracy\": accuracy_score(y_te, (prob_te >= thr_oof).astype(int)),\n",
    "                \"precision\": precision_score(\n",
    "                    y_te, (prob_te >= thr_oof).astype(int), zero_division=0\n",
    "                ),\n",
    "                \"recall\": recall_score(y_te, (prob_te >= thr_oof).astype(int)),\n",
    "                \"f1\": f1_score(y_te, (prob_te >= thr_oof).astype(int)),\n",
    "                \"best_params\": search.best_params_,\n",
    "                \"thr_source\": \"oof\",\n",
    "                \"thr_youden\": thr_oof,\n",
    "                \"sens_at_thr\": test_thr_metrics_oof[\"sensitivity\"],\n",
    "                \"spec_at_thr\": test_thr_metrics_oof[\"specificity\"],\n",
    "                \"ppv_at_thr\": test_thr_metrics_oof[\"ppv\"],\n",
    "                \"npv_at_thr\": test_thr_metrics_oof[\"npv\"],\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    test_metrics.to_csv(OUT_DIR / f\"{label}__test_metrics.csv\", index=False)\n",
    "\n",
    "    # (ì„ íƒ) ì°¸ê³ ìš©: Testì—ì„œ ë‹¤ì‹œ êµ¬í•œ thr_te ê²°ê³¼ëŠ” ë³„ë„ íŒŒì¼ë¡œë§Œ ì €ì¥ (ë¶€ë¡)\n",
    "    thr_te, tpr_te, fpr_te = youden_threshold(y_te.values, prob_te)\n",
    "    youden_te = tpr_te - fpr_te\n",
    "    test_thr_metrics_te = metrics_at_threshold(y_te.values, prob_te, thr_te)\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"label\": label,\n",
    "                \"model\": model_name,\n",
    "                \"split\": \"test\",\n",
    "                \"thr_source\": \"test\",\n",
    "                \"thr_youden\": thr_te,\n",
    "                \"youden_index\": youden_te,\n",
    "                **test_thr_metrics_te,\n",
    "            }\n",
    "        ]\n",
    "    ).to_csv(OUT_DIR / f\"{label}__youden_metrics_Test_fromTestThr.csv\", index=False)\n",
    "\n",
    "    # --- â­ï¸â­ï¸â­ï¸(B) Testì—ì„œ Youden index ê¸°ë°˜ ìµœì  threshold --- â­ï¸â­ï¸â­ï¸\n",
    "\n",
    "    test_pred = pd.DataFrame(\n",
    "        {\"label\": label, \"y_true\": y_te.values, \"y_prob\": prob_te, \"y_pred\": pred_te}\n",
    "    )\n",
    "    test_pred.to_csv(OUT_DIR / f\"{label}__test_predictions.csv\", index=False)\n",
    "\n",
    "    # Test ROC / Calibration / DCA\n",
    "    fpr, tpr, _ = roc_curve(y_te, prob_te)\n",
    "    plt.figure(figsize=(4.6, 4.2))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"AUC={auc_te:.3f}\")\n",
    "    plt.plot([0, 1], [0, 1], \"--\")\n",
    "    # --- â­ï¸â­ï¸â­ï¸ ì¶”ê°€ â­ï¸â­ï¸â­ï¸\n",
    "\n",
    "    def _tpr_fpr_at_thr(y_true, y_prob, thr):\n",
    "        yhat = (y_prob >= thr).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, yhat).ravel()\n",
    "        tpr = tp / (tp + fn + 1e-12)\n",
    "        fpr = fp / (fp + tn + 1e-12)\n",
    "        return tpr, fpr\n",
    "\n",
    "    tpr_oof_on_test, fpr_oof_on_test = _tpr_fpr_at_thr(y_te.values, prob_te, thr_oof)\n",
    "    plt.scatter(\n",
    "        [fpr_oof_on_test],\n",
    "        [tpr_oof_on_test],\n",
    "        s=30,\n",
    "        marker=\"o\",\n",
    "        label=f\"Youden thr={thr_oof:.3f}\",\n",
    "    )\n",
    "    # --- â­ï¸â­ï¸â­ï¸ ì¶”ê°€ â­ï¸â­ï¸â­ï¸\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(f\"ROC (Test) - {label} ({model_name})\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / f\"{label}__ROC_Test.png\")\n",
    "    plt.close()\n",
    "\n",
    "    pt, pp = calibration_curve(y_te, prob_te, n_bins=10)\n",
    "    plt.figure(figsize=(4.6, 4.2))\n",
    "    plt.plot(pp, pt, marker=\"o\")\n",
    "    plt.plot([0, 1], [0, 1], \"--\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Observed\")\n",
    "    plt.title(f\"Calibration (Test) - {label} ({model_name})\\nBrier={brier_te:.3f}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / f\"{label}__Calibration_Test.png\")\n",
    "    plt.close()\n",
    "\n",
    "    dca_te = decision_curve(y_te.values, prob_te)\n",
    "    plt.figure(figsize=(4.6, 4.2))\n",
    "    plt.plot(dca_te[\"threshold\"], dca_te[\"net_benefit\"], lw=2, label=\"Model\")\n",
    "    prev = y_te.mean()\n",
    "    treat_all = dca_te[\"threshold\"].apply(\n",
    "        lambda th: prev - (1 - prev) * (th / (1 - th))\n",
    "    )\n",
    "    plt.plot(dca_te[\"threshold\"], treat_all, \"--\", label=\"Treat-all\")\n",
    "    plt.plot(\n",
    "        dca_te[\"threshold\"],\n",
    "        np.zeros_like(dca_te[\"threshold\"]),\n",
    "        \"--\",\n",
    "        label=\"Treat-none\",\n",
    "    )\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Net benefit\")\n",
    "    plt.title(f\"DCA (Test) - {label} ({model_name})\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / f\"{label}__DCA_Test.png\")\n",
    "    plt.close()\n",
    "    dca_te.to_csv(OUT_DIR / f\"{label}__DCA_Test.csv\", index=False)\n",
    "\n",
    "    # SHAP (full Train ì¬í•™ìŠµ ëª¨ë¸ ê¸°ì¤€, Test íŠ¹ì„± ì‚¬ìš©)\n",
    "    print(\"  [SHAP] compute on Test ...\")\n",
    "\n",
    "    preproc = best_full.named_steps[\"preprocessor\"]\n",
    "    clf_final = best_full.named_steps[\"clf\"]\n",
    "\n",
    "    # 1) ì „ì²˜ë¦¬ í›„ ë°ì´í„° ì¤€ë¹„\n",
    "    rng = np.random.RandomState(42)\n",
    "    bg_idx = rng.choice(len(X_tr), size=min(200, len(X_tr)), replace=False)\n",
    "    X_bg_t = preproc.transform(X_tr.iloc[bg_idx])\n",
    "    X_te_t = preproc.transform(X_te)\n",
    "\n",
    "    # â­ï¸â›”ï¸â­ï¸â›”ï¸â­ï¸â›”ï¸ 2) ì „ì²˜ë¦¬ í›„ í”¼ì²˜ ì´ë¦„ + ì ‘ë‘ì‚¬ ì •ë¦¬ â­ï¸â›”ï¸â­ï¸â›”ï¸â­ï¸â›”ï¸â­ï¸â›”ï¸\n",
    "    # try:\n",
    "    #     raw_names = list(preproc.get_feature_names_out())\n",
    "    # except Exception:\n",
    "    #     raw_names = [f\"f{i}\" for i in range(X_te_t.shape[1])]\n",
    "    # 2) ì „ì²˜ë¦¬ í›„ í”¼ì²˜ ì´ë¦„\n",
    "    try:\n",
    "        raw_names = list(preproc.get_feature_names_out())\n",
    "    except Exception:\n",
    "        raw_names = [f\"f{i}\" for i in range(X_te_t.shape[1])]\n",
    "    # â­ï¸â›”ï¸â­ï¸â›”ï¸â­ï¸â›”ï¸ â­ï¸â›”ï¸â­ï¸â›”ï¸â­ï¸â›”ï¸â­ï¸â›”ï¸\n",
    "\n",
    "\n",
    "    # â­ï¸â›”ï¸â­ï¸â›”ï¸â­ï¸â›”ï¸ â­ï¸â›”ï¸â­ï¸â›”ï¸â­ï¸â›”ï¸â­ï¸â›”ï¸\n",
    "    feat_names = prettify_names(raw_names, NAME_MAP)\n",
    "    # â­ï¸â›”ï¸â­ï¸â›”ï¸â­ï¸â›”ï¸ â­ï¸â›”ï¸â­ï¸â›”ï¸â­ï¸â›”ï¸â­ï¸â›”ï¸\n",
    "\n",
    "    # 3) ëª¨ë¸ íƒ€ì…ë³„ Explainer (ë°°ê²½ ë°ì´í„° ì œê³µ â†’ interventional ê²½ê³  í•´ì†Œ)\n",
    "    try:\n",
    "        if isinstance(\n",
    "            clf_final,\n",
    "            (XGBClassifier, LGBMClassifier, CatBoostClassifier, RandomForestClassifier),\n",
    "        ):\n",
    "            explainer = shap.TreeExplainer(\n",
    "                clf_final,\n",
    "                data=X_bg_t,\n",
    "                feature_perturbation=\"interventional\",\n",
    "                model_output=\"probability\",\n",
    "            )\n",
    "            shap_expl = explainer(X_te_t)  # Explanation\n",
    "        elif isinstance(clf_final, LogisticRegression):\n",
    "            explainer = shap.LinearExplainer(clf_final, X_bg_t)\n",
    "            shap_expl = explainer(X_te_t)  # ndarray ë˜ëŠ” Explanation\n",
    "            if not isinstance(shap_expl, shap.Explanation):\n",
    "                shap_expl = shap.Explanation(\n",
    "                    values=shap_expl,\n",
    "                    base_values=np.zeros(X_te_t.shape[0]),\n",
    "                    data=X_te_t,\n",
    "                    feature_names=feat_names,\n",
    "                )\n",
    "        else:\n",
    "            explainer = shap.Explainer(clf_final, X_bg_t)\n",
    "            shap_expl = explainer(X_te_t)\n",
    "    except Exception:\n",
    "        explainer = shap.Explainer(clf_final, X_bg_t)\n",
    "        shap_expl = explainer(X_te_t)\n",
    "\n",
    "    # 4) (ì¤‘ìš”) ë‹¤ì¤‘ ì¶œë ¥ì´ë©´ ì–‘ì„± í´ë˜ìŠ¤(= index 1)ë§Œ ì„ íƒ â†’ beeswarm ì˜¤ë¥˜ í•´ê²°\n",
    "    try:\n",
    "        vals = shap_expl.values\n",
    "        if getattr(vals, \"ndim\", 2) == 3:\n",
    "            # (n, p, outputs) â†’ outputs=1 ì„ íƒ\n",
    "            shap_expl = shap_expl[:, :, 1]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 5) ì •ë¦¬ëœ í”¼ì²˜ëª… ì£¼ì…\n",
    "    try:\n",
    "        shap_expl.feature_names = feat_names\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 6) barì—ì„œ â€œsum of other featuresâ€ ì œê±°: ìƒìœ„ Kê°œë§Œ ë‚¨ê¸´ Explanation ìƒì„±\n",
    "    K = 20\n",
    "    # mean(|SHAP|) ê¸°ì¤€ ìƒìœ„ K ì¸ë±ìŠ¤\n",
    "    mean_abs = np.abs(np.array(shap_expl.values)).mean(axis=0)\n",
    "    topk_idx = np.argsort(mean_abs)[::-1][:K]\n",
    "    shap_top = shap_expl[:, topk_idx]  # Explanation ìŠ¬ë¼ì´ì‹± ì§€ì›\n",
    "\n",
    "    # 7) ì‹œê°í™” (ê³µì‹ API ì‚¬ìš©)\n",
    "    plt.figure()\n",
    "    shap.plots.beeswarm(\n",
    "        shap_expl,\n",
    "        max_display=K,\n",
    "        show=False,\n",
    "        group_remaining_features=False,\n",
    "    )\n",
    "    plt.title(f\"SHAP Summary (Test) - {label} ({model_name})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / f\"{label}__SHAP_summary_Test.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    shap.plots.bar(\n",
    "        shap_top, max_display=K, show=False\n",
    "    )  # group_remaining_features=False\n",
    "    plt.title(f\"SHAP Top Features (Test) - {label} ({model_name})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / f\"{label}__SHAP_bar_Test.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # =============================\n",
    "    # ğŸ”½ [NEW] SHAP ê°’ì„ CSVë¡œ ì €ì¥\n",
    "    # =============================\n",
    "    try:\n",
    "        # ---- ê¸°ë³¸ ë°°ì—´/ì´ë¦„ ì¤€ë¹„\n",
    "        shap_vals = np.asarray(shap_expl.values)  # (n_test, n_features)\n",
    "        n_te, p = shap_vals.shape\n",
    "        feat_names_arr = np.array(feat_names[:p])  # ì•ˆì „ ìŠ¬ë¼ì´ìŠ¤\n",
    "        row_ids = getattr(X_te, \"index\", np.arange(n_te))\n",
    "\n",
    "        # ---- (1) ë³€ìˆ˜ë³„ ìš”ì•½: ì¤‘ìš”ë„ ë° ë°©í–¥ì„±\n",
    "        mean_abs = np.abs(shap_vals).mean(axis=0)\n",
    "        mean_val = shap_vals.mean(axis=0)\n",
    "        std_val = shap_vals.std(axis=0)\n",
    "        med_abs = np.median(np.abs(shap_vals), axis=0)\n",
    "        q1_abs = np.quantile(np.abs(shap_vals), 0.25, axis=0)\n",
    "        q3_abs = np.quantile(np.abs(shap_vals), 0.75, axis=0)\n",
    "        nonzero_ratio = np.count_nonzero(shap_vals, axis=0) / float(n_te)\n",
    "\n",
    "        fi_df = (\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"label\": label,\n",
    "                    \"model\": model_name,\n",
    "                    \"feature\": feat_names_arr,\n",
    "                    \"mean_abs_shap\": mean_abs,\n",
    "                    \"mean_shap\": mean_val,\n",
    "                    \"std_shap\": std_val,\n",
    "                    \"median_abs_shap\": med_abs,\n",
    "                    \"q1_abs_shap\": q1_abs,\n",
    "                    \"q3_abs_shap\": q3_abs,\n",
    "                    \"nonzero_ratio\": nonzero_ratio,\n",
    "                }\n",
    "            )\n",
    "            .sort_values(\"mean_abs_shap\", ascending=False)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        fi_df.insert(0, \"rank\", np.arange(1, len(fi_df) + 1))\n",
    "        fi_df.to_csv(\n",
    "            OUT_DIR / f\"{label}__SHAP_feature_importance_Test.csv\", index=False\n",
    "        )\n",
    "\n",
    "        # ---- (2) ìƒìœ„ Kê°œë§Œ ë³„ë„ ì €ì¥ (ê·¸ë¦¼ max_displayì™€ í†µì¼)\n",
    "        topk = fi_df.head(K).copy()\n",
    "        topk.to_csv(OUT_DIR / f\"{label}__SHAP_top{K}_Test.csv\", index=False)\n",
    "\n",
    "        # ---- (3) í™˜ìÃ—ë³€ìˆ˜ wide ë§¤íŠ¸ë¦­ìŠ¤\n",
    "        shap_wide = pd.DataFrame(shap_vals, index=row_ids, columns=feat_names_arr)\n",
    "        shap_wide.index.name = \"row_id\"\n",
    "        shap_wide.to_csv(OUT_DIR / f\"{label}__SHAP_matrix_Test.csv\")\n",
    "\n",
    "        # âœ… (ì¶”ê°€) í…ŒìŠ¤íŠ¸ ë°ì´í„°(ì „ì²˜ë¦¬ í›„ feature ê°’) wide matrix\n",
    "        X_te_wide = pd.DataFrame(X_te_t, index=row_ids, columns=feat_names_arr)\n",
    "        X_te_wide.index.name = \"row_id\"\n",
    "\n",
    "        # ---- (4) long í¬ë§· (row_id, feature, shap_value, y_true, y_prob)\n",
    "        test_prob_series = pd.Series(prob_te, index=row_ids, name=\"y_prob\")\n",
    "        test_true_series = pd.Series(y_te.values, index=row_ids, name=\"y_true\")\n",
    "\n",
    "        shap_long = shap_wide.reset_index().melt(\n",
    "            id_vars=[\"row_id\"], var_name=\"feature\", value_name=\"shap_value\"\n",
    "        )\n",
    "\n",
    "        # âœ… (ì¶”ê°€) feature_value ì»¬ëŸ¼ ë³‘í•©\n",
    "        feat_long = X_te_wide.reset_index().melt(\n",
    "            id_vars=[\"row_id\"], var_name=\"feature\", value_name=\"feature_value\"\n",
    "        )\n",
    "        shap_long = shap_long.merge(feat_long, on=[\"row_id\", \"feature\"], how=\"left\")\n",
    "\n",
    "        shap_long = shap_long.merge(\n",
    "            test_true_series.reset_index(), on=\"row_id\", how=\"left\"\n",
    "        ).merge(test_prob_series.reset_index(), on=\"row_id\", how=\"left\")\n",
    "        shap_long.insert(0, \"label\", label)\n",
    "        shap_long.insert(1, \"model\", model_name)\n",
    "        shap_long.to_csv(OUT_DIR / f\"{label}__SHAP_long_Test.csv\", index=False)\n",
    "\n",
    "        print(\n",
    "            f\"  [SHAP] CSV saved: \"\n",
    "            f\"{label}__SHAP_feature_importance_Test.csv, \"\n",
    "            f\"{label}__SHAP_top{K}_Test.csv, \"\n",
    "            f\"{label}__SHAP_matrix_Test.csv, \"\n",
    "            f\"{label}__SHAP_long_Test.csv\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to write SHAP CSVs: {e}\")\n",
    "\n",
    "    # í†µí•© ìš”ì•½ ë°˜í™˜\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"model\": model_name,\n",
    "        \"train_oof_summary_path\": str(\n",
    "            (OUT_DIR / f\"{label}__train_fold_metrics.csv\").resolve()\n",
    "        ),\n",
    "        \"test_metrics_path\": str((OUT_DIR / f\"{label}__test_metrics.csv\").resolve()),\n",
    "        \"oof_pred_path\": str((OUT_DIR / f\"{label}__oof_predictions.csv\").resolve()),\n",
    "        \"test_pred_path\": str((OUT_DIR / f\"{label}__test_predictions.csv\").resolve()),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e647c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    manifest = []\n",
    "    for label, cfg in BEST_COMBOS.items():\n",
    "        res = run_for_label(\n",
    "            label=label,\n",
    "            model_name=cfg[\"model\"],\n",
    "            feature_set=cfg[\"feature_set\"],\n",
    "            random_state=42,\n",
    "        )\n",
    "        manifest.append(res)\n",
    "    pd.DataFrame(manifest).to_csv(OUT_DIR / \"final_runs_manifest.csv\", index=False)\n",
    "    print(\"\\nAll done. Results saved to:\", OUT_DIR)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}