{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Imputation x Oversampling Method Comparison\n",
    "\n",
    "Compares 4 imputation methods x 5 models x 5 time points.\n",
    "Uses both ROS (RandomOverSampler) and SMOTE for oversampling comparison."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from src.config import PROJECT_ROOT, MODEL_SEED\n",
    "from src.variables import CATEGORY_COLS, CODE_COLS\n",
    "from src.preprocessing import make_preprocessor\n",
    "from src.models import get_models_search_weighted, get_models_search_unweighted"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset definitions (4 imputation methods x 5 time points)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Paths ──\n",
    "IMP_BASE = PROJECT_ROOT / \"data/processed_imp/260106_split_corr_LLM_ADER/imputation\"\n",
    "\n",
    "datasets = {}\n",
    "for imp_method in [\"simple\", \"missforest\", \"hybrid\", \"mice\"]:\n",
    "    for label in [\"label_30d\", \"label_60d\", \"label_90d\", \"label_180d\", \"label_365d\"]:\n",
    "        key = f\"{imp_method}_{label}\"\n",
    "        datasets[key] = {\n",
    "            \"train_path\": str(IMP_BASE / f\"{imp_method}_imput/{imp_method}_{label}_train.csv\"),\n",
    "            \"test_path\": str(IMP_BASE / f\"{imp_method}_imput/{imp_method}_{label}_test.csv\"),\n",
    "            \"target\": label,\n",
    "        }\n",
    "\n",
    "print(f\"Total dataset configs: {len(datasets)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Output directories\n",
    "def setup_output(method_name):\n",
    "    base_out = PROJECT_ROOT / f\"results/new_analysis/imput_sampling_test/{method_name}\"\n",
    "    csv_out = base_out / \"final_output\"\n",
    "    csv_out.mkdir(parents=True, exist_ok=True)\n",
    "    return csv_out\n",
    "\n",
    "def load_data(train_path, test_path, target):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    X_train = df_train.drop(columns=[target])\n",
    "    y_train = df_train[target]\n",
    "    X_test = df_test.drop(columns=[target])\n",
    "    y_test = df_test[target]\n",
    "    return X_train, y_train, X_test, y_test"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipeline runner"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "auc_scorer = \"roc_auc\"\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=MODEL_SEED)\n",
    "\n",
    "def run_pipeline(X_train, y_train, X_test, y_test, ds_name,\n",
    "                 numeric_cols, categorical_cols, code_cols,\n",
    "                 models_search, oversampler=None):\n",
    "    pre = make_preprocessor(X_train, numeric_cols, categorical_cols, code_cols)\n",
    "    results = []\n",
    "\n",
    "    for name, (model, space) in tqdm(models_search.items(), desc=f\"[{ds_name}]\", leave=False):\n",
    "        steps = [(\"pre\", pre)]\n",
    "        if oversampler is not None:\n",
    "            steps.append((\"oversample\", oversampler))\n",
    "        steps.append((\"clf\", model))\n",
    "        pipe = ImbPipeline(steps)\n",
    "\n",
    "        bayes = BayesSearchCV(\n",
    "            pipe, search_spaces=space, n_iter=20, cv=cv,\n",
    "            scoring=auc_scorer, n_jobs=1, random_state=MODEL_SEED,\n",
    "        )\n",
    "        bayes.fit(X_train, y_train)\n",
    "\n",
    "        preds = bayes.predict(X_test)\n",
    "        proba = bayes.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        results.append({\n",
    "            \"dataset\": ds_name, \"model\": name,\n",
    "            \"accuracy\": accuracy_score(y_test, preds),\n",
    "            \"precision\": precision_score(y_test, preds, average=\"macro\", zero_division=0),\n",
    "            \"recall\": recall_score(y_test, preds, average=\"macro\", zero_division=0),\n",
    "            \"f1\": f1_score(y_test, preds, average=\"macro\"),\n",
    "            \"roc_auc\": roc_auc_score(y_test, proba),\n",
    "        })\n",
    "    return results"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run: ROS (RandomOverSampler)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "csv_out_ros = setup_output(\"ROS\")\n",
    "all_results_ros = {}\n",
    "\n",
    "for ds_name, cfg in tqdm(datasets.items(), desc=\"ROS Datasets\"):\n",
    "    X_tr, y_tr, X_te, y_te = load_data(cfg[\"train_path\"], cfg[\"test_path\"], cfg[\"target\"])\n",
    "    numeric_cols = [c for c in X_tr.columns if c not in CATEGORY_COLS + CODE_COLS]\n",
    "    key = f\"{ds_name}_oversample\"\n",
    "    all_results_ros[key] = run_pipeline(\n",
    "        X_tr, y_tr, X_te, y_te, key,\n",
    "        numeric_cols, [c for c in CATEGORY_COLS if c in X_tr.columns], [c for c in CODE_COLS if c in X_tr.columns],\n",
    "        get_models_search_unweighted(),\n",
    "        oversampler=RandomOverSampler(random_state=MODEL_SEED),\n",
    "    )\n",
    "\n",
    "df_ros = pd.concat([pd.DataFrame(v) for v in all_results_ros.values()], ignore_index=True)\n",
    "df_ros.to_csv(csv_out_ros / \"all_results.csv\", index=False)\n",
    "print(f\"ROS results saved: {len(df_ros)} rows\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "csv_out_smote = setup_output(\"SMOTE\")\n",
    "all_results_smote = {}\n",
    "\n",
    "for ds_name, cfg in tqdm(datasets.items(), desc=\"SMOTE Datasets\"):\n",
    "    X_tr, y_tr, X_te, y_te = load_data(cfg[\"train_path\"], cfg[\"test_path\"], cfg[\"target\"])\n",
    "    numeric_cols = [c for c in X_tr.columns if c not in CATEGORY_COLS + CODE_COLS]\n",
    "    key = f\"{ds_name}_oversample\"\n",
    "    all_results_smote[key] = run_pipeline(\n",
    "        X_tr, y_tr, X_te, y_te, key,\n",
    "        numeric_cols, [c for c in CATEGORY_COLS if c in X_tr.columns], [c for c in CODE_COLS if c in X_tr.columns],\n",
    "        get_models_search_unweighted(),\n",
    "        oversampler=SMOTE(random_state=MODEL_SEED),\n",
    "    )\n",
    "\n",
    "df_smote = pd.concat([pd.DataFrame(v) for v in all_results_smote.values()], ignore_index=True)\n",
    "df_smote.to_csv(csv_out_smote / \"all_results.csv\", index=False)\n",
    "print(f\"SMOTE results saved: {len(df_smote)} rows\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}